{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8zkSRPQ81W0e","executionInfo":{"status":"ok","timestamp":1708874165639,"user_tz":-330,"elapsed":24841,"user":{"displayName":"Devishree Nadar","userId":"03330865802865728893"}},"outputId":"e766473a-8b1f-4b4e-f3e0-5ae7026d61ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","# Define the path to your file\n","file_path = '/content/drive/MyDrive/Data/archive.zip'\n","\n","# Check if the file is a valid zip file\n","if not zipfile.is_zipfile(file_path):\n","    print(\"The provided file is not a valid zip file.\")\n","else:\n","    # Define the directory to extract the contents to\n","    extracted_folder = '/content/dataset'\n","\n","    # Create the target directory if it doesn't exist\n","    os.makedirs(extracted_folder, exist_ok=True)\n","\n","    # Extract the contents of the zip file\n","    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n","        zip_ref.extractall(extracted_folder)\n","\n","    # List the extracted contents\n","    extracted_files = os.listdir(extracted_folder)\n","    print(\"Extracted files:\", extracted_files)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2EOtDjFElRrP","executionInfo":{"status":"ok","timestamp":1708875736351,"user_tz":-330,"elapsed":90717,"user":{"displayName":"Devishree Nadar","userId":"03330865802865728893"}},"outputId":"5f43d966-0aa1-42bc-c7b7-44ac831d2759"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted files: ['Dataset']\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","# Define the CNN model\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Display the model summary\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XuwAtUnHrEXo","executionInfo":{"status":"ok","timestamp":1708855031515,"user_tz":-330,"elapsed":4535,"user":{"displayName":"Devishree Nadar","userId":"03330865802865728893"}},"outputId":"67b7a868-d5d4-4610-ed7b-3ffe2e9bef61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 222, 222, 32)      896       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 86528)             0         \n","                                                                 \n"," dense (Dense)               (None, 128)               11075712  \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 11169089 (42.61 MB)\n","Trainable params: 11169089 (42.61 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Define data generators\n","train_dir = '/content/dataset/Dataset/Train'\n","validation_dir = '/content/dataset/Dataset/Validation'\n","test_dir = '/content/dataset/Dataset/Test'\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    validation_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","# Train the model\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n","    epochs=4,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // validation_generator.batch_size\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ztx3jXzPrEaT","executionInfo":{"status":"ok","timestamp":1708862849908,"user_tz":-330,"elapsed":7709913,"user":{"displayName":"Devishree Nadar","userId":"03330865802865728893"}},"outputId":"5b9bf440-e2c8-4790-efcc-21850fad0352"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 140002 images belonging to 2 classes.\n","Found 39428 images belonging to 2 classes.\n","Epoch 1/4\n","4375/4375 [==============================] - 1924s 440ms/step - loss: 0.6263 - accuracy: 0.6444 - val_loss: 0.5540 - val_accuracy: 0.7309\n","Epoch 2/4\n","4375/4375 [==============================] - 1926s 440ms/step - loss: 0.4893 - accuracy: 0.7674 - val_loss: 0.4360 - val_accuracy: 0.8012\n","Epoch 3/4\n","4375/4375 [==============================] - 1890s 432ms/step - loss: 0.3876 - accuracy: 0.8303 - val_loss: 0.3932 - val_accuracy: 0.8290\n","Epoch 4/4\n","4375/4375 [==============================] - 1914s 437ms/step - loss: 0.3431 - accuracy: 0.8546 - val_loss: 0.4263 - val_accuracy: 0.8175\n"]}]},{"cell_type":"code","source":["# Save the model\n","model.save('/content/deepfake_detection_model.keras')"],"metadata":{"id":"qKWVGrJ6rPJa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","\n","# Load the saved model\n","model = load_model('/content/deepfake_detection_model.h5')\n","\n","# Define the test data generator\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Define the path to your test set\n","test_dir = '/content/dataset/Dataset/Test'\n","\n","# Create the test generator\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","# Evaluate the model on the test set\n","loss, accuracy = model.evaluate(test_generator)\n","print(\"Test Accuracy:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4K8jLtHrPL-","executionInfo":{"status":"ok","timestamp":1708863244395,"user_tz":-330,"elapsed":42446,"user":{"displayName":"Devishree Nadar","userId":"03330865802865728893"}},"outputId":"1f27205a-d263-4d65-e320-6cfe2add1686"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 10905 images belonging to 2 classes.\n","341/341 [==============================] - 23s 66ms/step - loss: 0.4921 - accuracy: 0.7688\n","Test Accuracy: 0.768821656703949\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","\n","# Load the saved model\n","model = load_model('/content/deepfake_detection_model.h5')"],"metadata":{"id":"jVeB3ns9rPOg","executionInfo":{"status":"ok","timestamp":1708875791294,"user_tz":-330,"elapsed":8989,"user":{"displayName":"Devishree Nadar","userId":"03330865802865728893"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.preprocessing import image\n","\n","# Path to your test image\n","image_path = '/content/IMG20211029180359.jpg'\n","# Load the image, resize it to 224x224 (same as training), and convert to array\n","img = image.load_img(image_path, target_size=(224, 224))\n","img_array = image.img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions for batch\n","\n","# Normalize the image\n","img_array = img_array / 255.0"],"metadata":{"id":"Zd3MiguMrPR3","executionInfo":{"status":"ok","timestamp":1708876977413,"user_tz":-330,"elapsed":400,"user":{"displayName":"Devishree Nadar","userId":"03330865802865728893"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Predict\n","prediction = model.predict(img_array)\n","\n","# If you have binary classification (real or fake)\n","if prediction[0] < 0.5:\n","    print(\"Prediction: Real\")\n","else:\n","    print(\"Prediction: Fake\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BryVJNnLMdS0","executionInfo":{"status":"ok","timestamp":1708876981710,"user_tz":-330,"elapsed":678,"user":{"displayName":"Devishree Nadar","userId":"03330865802865728893"}},"outputId":"054b04de-b577-4088-874a-dde2d793d921"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 82ms/step\n","Prediction: Real\n"]}]}]}