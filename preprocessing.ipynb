{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPqcyN4laASm68ysjtkUOI/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1d163a9d94cf4d7aa707a9ce1d2b7e46":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fcef084673434e33aa8a30dceb451b98","IPY_MODEL_a334a03805d14d4f9831f0fccf90c3ce","IPY_MODEL_b11c5b6083bb47a297c042dedd03a29a"],"layout":"IPY_MODEL_b636656b95254faa8b841fc695c2eb06"}},"fcef084673434e33aa8a30dceb451b98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6661b2ea5ea459497944eba9306aa9f","placeholder":"​","style":"IPY_MODEL_df1be9a115eb4c48a80b98790723018a","value":"100%"}},"a334a03805d14d4f9831f0fccf90c3ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebd20b924b864931ba02c163a795d9c3","max":35,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e87e505fb42476d9e455fb0d770ac6f","value":35}},"b11c5b6083bb47a297c042dedd03a29a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78810f73122b4909aa33509f21a9515b","placeholder":"​","style":"IPY_MODEL_03bd7c7daea94e82bb4c18451230c76d","value":" 35/35 [30:50&lt;00:00, 53.06s/it]"}},"b636656b95254faa8b841fc695c2eb06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6661b2ea5ea459497944eba9306aa9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df1be9a115eb4c48a80b98790723018a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebd20b924b864931ba02c163a795d9c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e87e505fb42476d9e455fb0d770ac6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78810f73122b4909aa33509f21a9515b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03bd7c7daea94e82bb4c18451230c76d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NiKucZ6IMU4M","executionInfo":{"status":"ok","timestamp":1708773473001,"user_tz":-330,"elapsed":5087,"user":{"displayName":"Advika Sawant","userId":"15624361264755745122"}},"outputId":"a013d23b-a305-4d8b-9a0c-4aad2c838902"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#Mount our google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["#before running this please change the RUNTIME to GPU (Runtime -> Change runtime type -> set harware accelarotor as GPU)\n","#download and unzip the data from google drive Colab environment\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","#use only file id of the link\n","#Note: Below link is just an example, Not an actual link. Actual Links are in ReadMe file\n","#https://drive.google.com/file/d/1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07/view?usp=sharing\n","#https://drive.google.com/drive/folders/11HCRwCeU5TNe7g4MRnyaFsUIbaTei4Kh?usp=drive_link\n","url = '11HCRwCeU5TNe7g4MRnyaFsUIbaTei4Kh'\n","gdd.download_file_from_google_drive(file_id = url,dest_path='./data.zip',unzip=True)"],"metadata":{"id":"octIeml_MaYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#To get the average frame count\n","import json\n","import glob\n","import numpy as np\n","import cv2\n","import copy\n","#change the path accordingly\n","video_files =  glob.glob('/content/drive/My Drive/Dataset/*.mp4')\n","#video_files1 =  glob.glob('/content/dfdc_train_part_0/*.mp4')\n","#video_files += video_files1\n","frame_count = []\n","for video_file in video_files:\n","  cap = cv2.VideoCapture(video_file)\n","  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<150):\n","    video_files.remove(video_file)\n","    continue\n","  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n","print(\"frames\" , frame_count)\n","print(\"Total number of videos: \" , len(frame_count))\n","print('Average frame per video:',np.mean(frame_count))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ii3naItoMab8","executionInfo":{"status":"ok","timestamp":1708773479564,"user_tz":-330,"elapsed":1234,"user":{"displayName":"Advika Sawant","userId":"15624361264755745122"}},"outputId":"1b67e968-e972-4aab-a158-c4eaf146e9cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["frames [300, 300, 300, 300, 301, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300]\n","Total number of videos:  39\n","Average frame per video: 300.02564102564105\n"]}]},{"cell_type":"code","source":["# to extract frame\n","def frame_extract(path):\n","  vidObj = cv2.VideoCapture(path)\n","  success = 1\n","  while success:\n","      success, image = vidObj.read()\n","      if success:\n","          yield image\n","!pip3 install face_recognition\n","!mkdir '/content/drive/My Drive/FF_REAL_Face_only_data'\n","import torch\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Dataset\n","import os\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import face_recognition\n","from tqdm.autonotebook import tqdm\n","# process the frames\n","def create_face_videos(path_list,out_dir):\n","  already_present_count =  glob.glob(out_dir+'*.mp4')\n","  print(\"No of videos already present \" , len(already_present_count))\n","  for path in tqdm(path_list):\n","    out_path = os.path.join(out_dir,path.split('/')[-1])\n","    file_exists = glob.glob(out_path)\n","    if(len(file_exists) != 0):\n","      print(\"File Already exists: \" , out_path)\n","      continue\n","    frames = []\n","    flag = 0\n","    face_all = []\n","    frames1 = []\n","    out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n","    for idx,frame in enumerate(frame_extract(path)):\n","      #if(idx % 3 == 0):\n","      if(idx <= 150):\n","        frames.append(frame)\n","        if(len(frames) == 4):\n","          faces = face_recognition.batch_face_locations(frames)\n","          for i,face in enumerate(faces):\n","            if(len(face) != 0):\n","              top,right,bottom,left = face[0]\n","            try:\n","              out.write(cv2.resize(frames[i][top:bottom,left:right,:],(112,112)))\n","            except:\n","              pass\n","          frames = []\n","    try:\n","      del top,right,bottom,left\n","    except:\n","      pass\n","    out.release()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":515},"id":"d3YU5oKaMafT","executionInfo":{"status":"error","timestamp":1708776018171,"user_tz":-330,"elapsed":9512,"user":{"displayName":"Advika Sawant","userId":"15624361264755745122"}},"outputId":"c8c88564-6c16-4aaa-d403-b4a59ef7cf15"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: face_recognition in /usr/local/lib/python3.10/dist-packages (1.3.0)\n","Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (0.3.0)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.25.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n","mkdir: cannot create directory ‘/content/drive/My Drive/FF_REAL_Face_only_data’: File exists\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-lbzqyazs/dlib_63ae84912bcb4801aa04a16211c0ac1a/dlib/cuda/gpu_data.cpp:204. code: 35, reason: CUDA driver version is insufficient for CUDA runtime version","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-1758d635a1e7>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# process the frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.2.3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_face_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_landmarks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcnn_face_detection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detector_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcnn_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_face_detection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mface_recognition_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_recognition_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-lbzqyazs/dlib_63ae84912bcb4801aa04a16211c0ac1a/dlib/cuda/gpu_data.cpp:204. code: 35, reason: CUDA driver version is insufficient for CUDA runtime version"]}]},{"cell_type":"code","source":["create_face_videos(video_files,'/content/drive/My Drive/Face_only_data/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["1d163a9d94cf4d7aa707a9ce1d2b7e46","fcef084673434e33aa8a30dceb451b98","a334a03805d14d4f9831f0fccf90c3ce","b11c5b6083bb47a297c042dedd03a29a","b636656b95254faa8b841fc695c2eb06","a6661b2ea5ea459497944eba9306aa9f","df1be9a115eb4c48a80b98790723018a","ebd20b924b864931ba02c163a795d9c3","5e87e505fb42476d9e455fb0d770ac6f","78810f73122b4909aa33509f21a9515b","03bd7c7daea94e82bb4c18451230c76d"]},"id":"TZ7Vp9tpSADx","executionInfo":{"status":"ok","timestamp":1708766029372,"user_tz":-330,"elapsed":456666,"user":{"displayName":"Advika Sawant","userId":"15624361264755745122"}},"outputId":"26afa396-65be-4e6b-ec5f-4b1ed5616638"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["No of videos already present  0\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d163a9d94cf4d7aa707a9ce1d2b7e46","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/35 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}]}]}